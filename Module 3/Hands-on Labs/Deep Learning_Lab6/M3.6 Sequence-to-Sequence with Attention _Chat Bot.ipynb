{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAIST Summer Session 2018\n",
    "\n",
    "## Simple Chat Bot using Sequence-to-Sequence with Attention (08.23.2018)\n",
    "\n",
    "- A simple chat bot based on fictional conversations extracted from raw movie scripts.\n",
    "- The training dataset is obtained from https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html.\n",
    "- This code is adapted from https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MAX_LENGTH = 5\n",
    "hidden_size = 300\n",
    "learning_rate = 0.01\n",
    "dropout_p = 0.1\n",
    "n_layers = 1\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = re.sub('[.,/?!-]', '', s)\n",
    "    return s.lower()\n",
    "\n",
    "\n",
    "def lengthfilter(pairs):\n",
    "    return [pair for pair in pairs if len(pair[0].split(' ')) < MAX_LENGTH and len(pair[1].split(' ')) < MAX_LENGTH]\n",
    "\n",
    "def readLangs(lang1, lang2):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Load the data# Load  \n",
    "    lines = open('chat bot\\\\movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "    conv_lines = open('chat bot\\\\movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "\n",
    "    # Create a dictionary to map each line's id with its text# Creat \n",
    "    id2line = {}\n",
    "    for line in lines:\n",
    "        _line = line.split(' +++$+++ ')\n",
    "        if len(_line) == 5:\n",
    "            id2line[_line[0]] = _line[4]\n",
    "        \n",
    "\n",
    "    # Create a list of all of the conversations' lines' ids.\n",
    "    convs = [ ]\n",
    "    for line in conv_lines[:-1]:\n",
    "        _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "        convs.append(_line.split(','))\n",
    "    \n",
    "\n",
    "    # Sort the sentences into questions (inputs) and answers (targets)\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for conv in convs:\n",
    "        for i in range((len(conv)-1)):\n",
    "            questions.append(id2line[conv[i]])\n",
    "            answers.append(id2line[conv[i+1]])\n",
    "     \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(x),normalizeString(y)] for x, y in zip(questions, answers)]\n",
    "    \n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, small=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    random.shuffle(pairs)\n",
    "    pairs = lengthfilter(pairs)\n",
    "    if small:\n",
    "        pairs = pairs[: int(len(pairs)/10 * 0.9)]     \n",
    "        \n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 2273 sentence pairs\n",
      "Counted words:\n",
      "questions 1667\n",
      "answer 1558\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('questions', 'answer', small=True) # \"Small=True\" option will draw 10% random sample from dataset \n",
    "\n",
    "training = pairs[: int(len(pairs) * 0.9)]\n",
    "test = pairs[int(len(pairs) * 0.9):]\n",
    "\n",
    "training_pairs = [tensorsFromPair(training[i]) for i in range(len(training))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  he killed her\n",
      "Answer:  what\n",
      "Question:  it'l be alright\n",
      "Answer:  it will\n",
      "Question:  maverick\n",
      "Answer:  yeah cougar\n",
      "Question:  my wife\n",
      "Answer:  what's it like\n",
      "Question:  you've seen it\n",
      "Answer:  yes\n",
      "Question:  fifteen years yeah\n",
      "Answer:  yeah oh god bless\n",
      "Question:  no  no\n",
      "Answer:  no\n",
      "Question:  no we're not\n",
      "Answer:  we're not\n",
      "Question:  that means topsecret cooper\n",
      "Answer:  i heard it\n",
      "Question:  good night\n",
      "Answer:  good night\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pair = random.choice(pairs)\n",
    "    print('Question: ', pair[0])\n",
    "    print('Answer: ', pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output,(hidden, cell) = self.lstm(embedded,(hidden, cell))\n",
    "        return output, hidden, cell\n",
    "\n",
    "    def init_hidden_cell(self):\n",
    "        hidden = torch.zeros(self.n_layers, 1, self.hidden_size, device=device)\n",
    "        cell = torch.zeros(self.n_layers, 1, self.hidden_size, device=device)\n",
    "        return hidden,cell\n",
    "    \n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, n_layers)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output,(hidden, cell) = self.lstm(output,(hidden, cell))\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, cell, attn_weights\n",
    "\n",
    "    def init_hidden_cell(self):\n",
    "        hidden = torch.zeros(self.n_layers, 1, self.hidden_size, device=device)\n",
    "        cell = torch.zeros(self.n_layers, 1, self.hidden_size, device=device)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the seq2seq model\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words,n_layers, dropout_p=dropout_p).to(device)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(attn_decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder.train()\n",
    "    decoder.train()    \n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    # Encoding\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size,  device=device)\n",
    "    encoder_hidden, encoder_cell = encoder.init_hidden_cell()\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        \n",
    "    # Decoding using the encoded representation          \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell = encoder_cell\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  1m 46s (- 33m 41s) (5%) 4.0383\n",
      "Epoch 2  3m 41s (- 33m 11s) (10%) 3.8309\n",
      "Epoch 3  5m 26s (- 30m 47s) (15%) 3.7838\n",
      "Epoch 4  7m 10s (- 28m 42s) (20%) 3.6605\n",
      "Epoch 5  9m 2s (- 27m 7s) (25%) 3.5835\n",
      "Epoch 6  10m 48s (- 25m 14s) (30%) 3.4382\n",
      "Epoch 7  12m 38s (- 23m 27s) (35%) 3.2893\n",
      "Epoch 8  14m 35s (- 21m 52s) (40%) 3.1549\n",
      "Epoch 9  16m 26s (- 20m 5s) (45%) 2.9455\n",
      "Epoch 10  18m 16s (- 18m 16s) (50%) 2.7675\n",
      "Epoch 11  20m 13s (- 16m 32s) (55%) 2.5604\n",
      "Epoch 12  22m 6s (- 14m 44s) (60%) 2.3938\n",
      "Epoch 13  24m 1s (- 12m 55s) (65%) 2.1706\n",
      "Epoch 14  26m 1s (- 11m 9s) (70%) 1.8884\n",
      "Epoch 15  27m 57s (- 9m 19s) (75%) 1.7726\n",
      "Epoch 16  30m 0s (- 7m 30s) (80%) 1.4914\n",
      "Epoch 17  31m 59s (- 5m 38s) (85%) 1.3481\n",
      "Epoch 18  33m 57s (- 3m 46s) (90%) 1.1687\n",
      "Epoch 19  36m 3s (- 1m 53s) (95%) 1.0810\n",
      "Epoch 20  38m 4s (- 0m 0s) (100%) 0.8820\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "print_loss_total = 0\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, n_epochs+1):    \n",
    "    for i in range(len(training_pairs)):\n",
    "        training_pair = random.choice(training_pairs)\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = train(input_tensor, target_tensor, encoder, attn_decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "    \n",
    "    print_loss_average = print_loss_total / len(training_pairs)    \n",
    "    print('Epoch {}'.format(epoch),' {} ({:.0f}%) {:.4f}'.format(time_since(start, epoch / n_epochs), epoch / n_epochs * 100, print_loss_average))\n",
    "    print_loss_total = 0\n",
    "    \n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    encoder.eval()\n",
    "    decoder.eval()   \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden, encoder_cell = encoder.init_hidden_cell()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden,decoder_cell, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see how the model works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  hi\n",
      "Truth:  hi\n",
      "Predicted:  hi want a drink <EOS>\n",
      "\n",
      "Source:  you think i'm crazy\n",
      "Truth:  i think you're different\n",
      "Predicted:  you got a <EOS>\n",
      "\n",
      "Source:  not that one\n",
      "Truth:  not that one\n",
      "Predicted:  i like like <EOS>\n",
      "\n",
      "Source:  that's it\n",
      "Truth:  that's it\n",
      "Predicted:  i can't <EOS>\n",
      "\n",
      "Source:  he's dead\n",
      "Truth:  dead\n",
      "Predicted:  so <EOS>\n",
      "\n",
      "Source:  what right now\n",
      "Truth:  uhhuh\n",
      "Predicted:  gimme a goddamn <EOS>\n",
      "\n",
      "Source:  jake\n",
      "Truth:  do what i say\n",
      "Predicted:  i'm <EOS>\n",
      "\n",
      "Source:  drive  drive away\n",
      "Truth:  what happened\n",
      "Predicted:  i'm the driver <EOS>\n",
      "\n",
      "Source:  for keeps\n",
      "Truth:  for keeps\n",
      "Predicted:  thank you <EOS>\n",
      "\n",
      "Source:   hi\n",
      "Truth:  well c'mere young fella\n",
      "Predicted:  i knowi know <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pair = random.choice(test)\n",
    "    print('Source: ', pair[0])\n",
    "    print('Truth: ', pair[1])\n",
    "    output_words, attentions = evaluate(encoder, attn_decoder, pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('Predicted: ', output_sentence)\n",
    "    print('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  what is your name\n",
      "Answer:  mulet <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "own_sentence = 'What is your name?'\n",
    "own_sentence = normalizeString(own_sentence)\n",
    "print('Question: ', own_sentence)\n",
    "output_words, attentions = evaluate(encoder, attn_decoder, own_sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print('Answer: ', output_sentence)\n",
    "print('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
